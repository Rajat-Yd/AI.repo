{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "10Zol9E5OneuONdHPawFQAg1hb5D7OGnT",
      "authorship_tag": "ABX9TyOwoNYV4ksWys9l00hlGc0I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajat-Yd/AI.repo/blob/main/mcq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BHe8gF3usUx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import traceback\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "25myGqdg1dFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "EZl7DkBc18p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"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\"\n",
        "llm = ChatOpenAI(openai_api_key = openai_api_key, model_name=\"gpt-3.5-turbo\", temperature=0.5)"
      ],
      "metadata": {
        "id": "9GeUuMVhA0Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "8RbnGzwyU_ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESPONSE_JSON = {\n",
        "    \"1\":{\n",
        "        \"mcq\": \"Muliple choice question\",\n",
        "        \"options\":{\n",
        "            \"a\":\"choice here\",\n",
        "            \"b\":\"chice here\",\n",
        "            \"c\":\"choice here\",\n",
        "            \"d\":\"choice here\",\n",
        "        },\n",
        "        \"correct\": \"Correct answer\"\n",
        "    },\n",
        "       \"2\":{\n",
        "        \"mcq\": \"Muliple choice question\",\n",
        "        \"options\":{\n",
        "            \"a\":\"choice here\",\n",
        "            \"b\":\"chice here\",\n",
        "            \"c\":\"choice here\",\n",
        "            \"d\":\"choice here\",\n",
        "        },\n",
        "        \"correct\": \"Correct answer\"\n",
        "    },\n",
        "       \"3\":{\n",
        "        \"mcq\": \"Muliple choice question\",\n",
        "        \"options\":{\n",
        "            \"a\":\"choice here\",\n",
        "            \"b\":\"chice here\",\n",
        "            \"c\":\"choice here\",\n",
        "            \"d\":\"choice here\",\n",
        "        },\n",
        "        \"correct\": \"Correct answer\"\n",
        "    },\n",
        "       \"4\":{\n",
        "        \"mcq\": \"Muliple choice question\",\n",
        "        \"options\":{\n",
        "            \"a\":\"choice here\",\n",
        "            \"b\":\"chice here\",\n",
        "            \"c\":\"choice here\",\n",
        "            \"d\":\"choice here\",\n",
        "        },\n",
        "        \"correct\": \"Correct answer\"\n",
        "    },\n",
        "       \"5\":{\n",
        "        \"mcq\": \"Muliple choice question\",\n",
        "        \"options\":{\n",
        "            \"a\":\"choice here\",\n",
        "            \"b\":\"chice here\",\n",
        "            \"c\":\"choice here\",\n",
        "            \"d\":\"choice here\",\n",
        "        },\n",
        "        \"correct\": \"Correct answer\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "aCYNEDhAZ7kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPLATE = \"\"\"\n",
        "Text:{text}\n",
        "You are an expert MCQ maker . Given the above  text , it is your job to \\\n",
        "create a quiz of {number} multiple choice questions fro {subject} students in {tone}tone.\n",
        "Make sure the questions are not repeated and check all the questions to be confirming the text as well.\n",
        "Mkae sure to formate your response like RESPONSE_JSON below and use it as a guide. \\\n",
        "Ensure to make {number} MCQs\n",
        "### RESPONSE_JSON\n",
        "{response_json}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-pK6QEtQX18n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_prompt_gen = PromptTemplate(\n",
        "    input_variables = [\"text\",\"numbers\",\"subject\",\"tone\",\"response_json\" ],\n",
        "    template = TEMPLATE\n",
        ")"
      ],
      "metadata": {
        "id": "Lgn-DAcOU_wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt_gen, output_key=\"quiz\", verbose=True)"
      ],
      "metadata": {
        "id": "uvN4tdIMU_y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPLATE2= \"\"\"\n",
        "You are an expert english grammarian and writer .Given a MCQ Quiz for {subject} students.\\\n",
        "You need to evaluate teh complexity of the question and give a complete analysis of the quiz. Only use at amx 50 word for complexity analysis\n",
        "if the quiz is not as per with the cognitive and anlytical abilities of students, \\\n",
        "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the students Quiz_MCQs:\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h2ho8yDUU_2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_evaluation_prompt = PromptTemplate(input_variables=[\"subject\", \"quiz\"], template = TEMPLATE)"
      ],
      "metadata": {
        "id": "c3EAEFsGVAI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_chain = LLMChain(llm=llm, prompt = quiz_evaluation_prompt, output_key =\"review\", verbose= True)"
      ],
      "metadata": {
        "id": "38i31m17VAL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
        "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
      ],
      "metadata": {
        "id": "Vtf_UFwmqFbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Data.txt\"\n",
        "with open(file_path, 'r') as file:\n",
        "  TEXT = file.read()"
      ],
      "metadata": {
        "id": "1GYz4oblqFd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dumps(RESPONSE_JSON)"
      ],
      "metadata": {
        "id": "i9sgMPxZqFjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER = 5\n",
        "SUBJECT = \"Machine learning \"\n",
        "TONE = \"Simple\""
      ],
      "metadata": {
        "id": "_HGQtnEs2ASU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "  response = generate_evaluate_chain(\n",
        "      {\n",
        "          \"text\":TEXT,\n",
        "          \"number\":NUMBER,\n",
        "          \"subject\":SUBJECT,\n",
        "          \"tone\":TONE,\n",
        "          \"response_json\": json.dumps(RESPONSE_JSON)\n",
        "      }\n",
        "  )"
      ],
      "metadata": {
        "id": "8oxXdZ4k0QlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total Tokens:{cb.total_tokens}')\n",
        "print(f'Prompt Tokens:{cb.prompt_tokens}')\n",
        "print(f'Completion Tokens:{cb.completion_tokens}')\n",
        "print(f'Total Cost:{cb.total_cost}')"
      ],
      "metadata": {
        "id": "uA3tBggc2Lqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz = response.get(\"Quiz\")"
      ],
      "metadata": {
        "id": "TegHqIV_4pXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz = json.load(quiz)"
      ],
      "metadata": {
        "id": "kawanfMR5FGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_table_data = []\n",
        "    for key, value in quiz.items():\n",
        "      mcq = value [\"mcq\"]\n",
        "      options = \" | \".join(\n",
        "          [\n",
        "              f'{option}:{option_value}'\n",
        "              for option. option_value in value {'options'}.items()\n",
        "          ]\n",
        "      )\n",
        "    correct =  value[\"correct\"]\n",
        "    quiz_table_data.append({\"MCQ:mcq\", \"Choices:\"options, \"Correc\" correct})"
      ],
      "metadata": {
        "id": "0HLRaiGf5N8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz = pd.DataFrame(quiz_table_data)"
      ],
      "metadata": {
        "id": "5pIPx4twBHTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz.do_csv(\"Mchine learning.csv\", index = False)"
      ],
      "metadata": {
        "id": "3GD5h_V8BHWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "9mky5zWLBHZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datetime.now()"
      ],
      "metadata": {
        "id": "qjZHJNovBI1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQj3Xc1f6Gs3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}